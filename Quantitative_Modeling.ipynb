{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81408d4d-0173-4400-ab2f-037af5b7cd47",
   "metadata": {},
   "source": [
    "# Quant Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1b291-5a3b-472e-b861-1ed45c3d2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from kneed import KneeLocator\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71102425-5cc5-4230-9ce8-a7c0aa7f1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_map = pd.read_csv('quant_map.csv')\n",
    "\n",
    "quant_map_loaded = {key: group.drop(columns=['key']) for key, group in quant_map.groupby('key')}\n",
    "\n",
    "quant_map = quant_map_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958919e4-4067-4dd1-8cc2-81411de128c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id_mapping = pd.read_csv('player_id_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17583278-fd47-4fd6-8a0a-461ad3eba3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elbow(pos_mapping):\n",
    "    def elbow(df, name, ax):\n",
    "        player_ids = df['player_id\"']\n",
    "        df_no_id = df.drop(columns=['player_id'])\n",
    "\n",
    "        inertias = []\n",
    "        cluster_range = range(2, min(len(df_no_id), 15))\n",
    "        \n",
    "        for k in cluster_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(df_no_id)  \n",
    "            inertias.append(kmeans.inertia_)\n",
    "\n",
    "        knee_locator = KneeLocator(cluster_range, inertias, curve=\"convex\", direction=\"decreasing\")\n",
    "        optimal_k = knee_locator.knee\n",
    "\n",
    "        # if no optimal_k set to 3\n",
    "        if optimal_k is None:\n",
    "            optimal_k = 3\n",
    "\n",
    "        ax.plot(cluster_range, inertias, marker='o')\n",
    "        ax.axvline(x=optimal_k, color=\"r\", linestyle=\"--\", label=f\"Optimal k={optimal_k}\")\n",
    "        ax.set_title(f'Elbow Method {name}')\n",
    "        ax.set_xlabel('Number of Clusters')\n",
    "        ax.set_ylabel('Inertia')\n",
    "        ax.legend()\n",
    "    \n",
    "        return optimal_k, player_ids\n",
    "\n",
    "    quantitative = {}\n",
    "    \n",
    "    num_positions = len(pos_mapping)\n",
    "    rows = (num_positions // 3) + 1\n",
    "    cols = 3\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten() \n",
    "    \n",
    "    for i, (pos, df) in enumerate(pos_mapping.items()):\n",
    "        opt_k, player_ids = elbow(df, pos, axes[i])\n",
    "        df['player_id'] = player_ids  \n",
    "        quantitative[pos] = {'DataFrame': df, 'Optimal_k': opt_k}\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return quantitative\n",
    "\n",
    "quantitative = get_elbow(quant_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f3707-4313-422f-9442-f9f6009f681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(lib, top_n=3, random_seed = 42):\n",
    "    feature_selected_lib = {}\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for pos, value in lib.items():\n",
    "        df = value['DataFrame']\n",
    "\n",
    "        player_ids = df['player_id']\n",
    "        df_no_id = df.drop(columns=['player_id'])\n",
    "\n",
    "        random_labels = np.random.randint(0, 2, size=len(df_no_id))  \n",
    "\n",
    "        # Random forst to find important features\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
    "        rf.fit(df_no_id, random_labels)\n",
    "        feature_importances = rf.feature_importances_\n",
    "\n",
    "        importance_df = pd.DataFrame({'Feature': df_no_id.columns, 'Importance': feature_importances})\n",
    "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        selected_features = importance_df['Feature'][:top_n].tolist()\n",
    "\n",
    "        df_selected = df[selected_features].copy()\n",
    "        df_selected['player_id'] = player_ids\n",
    "\n",
    "        feature_selected_lib[pos] = {'DataFrame': df_selected, 'Optimal_k': value['Optimal_k']}\n",
    "        \n",
    "        print(f'Position: {pos} - Selected Features: {selected_features}')\n",
    "\n",
    "    return feature_selected_lib\n",
    "\n",
    "filtered_quantitative = select_important_features(quantitative, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffe8f6-c83b-40ef-b6a7-c00aa103ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(lib):\n",
    "    def evaluate_kmeans(params, data):\n",
    "        model = KMeans(**params)\n",
    "        labels = model.fit_predict(data)\n",
    "        score = silhouette_score(data, labels)\n",
    "        return score\n",
    "\n",
    "    for pos, value in lib.items():\n",
    "        df = value['DataFrame']\n",
    "        k = value['Optimal_k']\n",
    "\n",
    "        player_ids = df['player_id']\n",
    "        df_no_id = df.drop(columns=['player_id'])  \n",
    "\n",
    "        param_grid = {\n",
    "            'n_clusters': [k],\n",
    "            'init': ['k-means++', 'random'],\n",
    "            'max_iter': [50, 100, 300], \n",
    "            'random_state': [42]\n",
    "        }\n",
    "\n",
    "        param_grid = ParameterGrid(param_grid)\n",
    "        best_params = None\n",
    "        best_score = -1\n",
    "\n",
    "        # Grid Search for hyperparameter tuning \n",
    "        for params in param_grid:\n",
    "            score = evaluate_kmeans(params, df_no_id)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "\n",
    "        optimal_kmeans = KMeans(**best_params)\n",
    "        cluster_labels = optimal_kmeans.fit_predict(df_no_id)\n",
    "\n",
    "        # reattaching cluster labels and player_id\n",
    "        df[\"cluster\"] = cluster_labels.astype(str)\n",
    "        df[\"player_id\"] = player_ids  \n",
    "\n",
    "        lib[pos]['DataFrame'] = df\n",
    "\n",
    "    return {pos: info['DataFrame'] for pos, info in lib.items()}\n",
    "\n",
    "quant_cluster= clustering(filtered_quantitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bbe8f-1303-4da3-8de1-7ffd493ae008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_with_table(quantitative, player_id_mapping):\n",
    "    \n",
    "    for pos, df in quantitative.items():\n",
    "\n",
    "        df = df.reset_index()\n",
    "        df = df.merge(player_id_mapping, on='player_id', how='left')\n",
    "\n",
    "        df['cluster'] = df['cluster'].astype(int)\n",
    "        df['cluster'] = pd.Categorical(df['cluster'], categories=sorted(df['cluster'].unique()), ordered=True)\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_features = pca.fit_transform(\n",
    "            df.drop(columns=['cluster', 'player_name', 'pos_abbr', 'player_id'], errors='ignore')\n",
    "        )\n",
    "\n",
    "        # Add PCA features back to the DataFrame\n",
    "        df['PCA1'] = pca_features[:, 0]\n",
    "        df['PCA2'] = pca_features[:, 1]\n",
    "\n",
    "\n",
    "        sorted_clusters = sorted(df['cluster'].unique())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        scatter_plot = sns.scatterplot(\n",
    "            data=df,\n",
    "            x='PCA1',\n",
    "            y='PCA2',\n",
    "            hue='cluster',\n",
    "            palette='viridis',\n",
    "            s=100,\n",
    "            alpha=0.7,\n",
    "            hue_order=sorted_clusters\n",
    "        )\n",
    "        \n",
    "        plt.title(f'Cluster Visualization of {pos} (PCA)', fontsize=16)\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "        cluster_info = []\n",
    "        grouped = df.groupby('cluster', observed = True)\n",
    "        for cluster, group in grouped:\n",
    "            cluster_text = [f\"Cluster {cluster}\"] + [f\"{row['player_name']} ({row['pos_abbr']})\" for _, row in group.iterrows()]\n",
    "            cluster_info.append(cluster_text)\n",
    "\n",
    "        max_rows_per_column = 20\n",
    "        flattened_table = []\n",
    "        for cluster_text in cluster_info:\n",
    "            flattened_table.extend(cluster_text)\n",
    "            flattened_table.append(\"\")\n",
    "\n",
    "\n",
    "        num_columns = math.ceil(len(flattened_table) / max_rows_per_column)\n",
    "        table_data = [\n",
    "            flattened_table[i * max_rows_per_column:(i + 1) * max_rows_per_column]\n",
    "            for i in range(num_columns)\n",
    "        ]\n",
    "\n",
    "        max_col_length = max(len(column) for column in table_data)\n",
    "        table_data = [\n",
    "            column + [''] * (max_col_length - len(column)) for column in table_data\n",
    "        ]\n",
    "\n",
    "\n",
    "        table_ax = plt.gcf().add_axes([0.1, -0.4, 0.8, 0.3])\n",
    "        table_ax.axis('off')\n",
    "        table = table_ax.table(\n",
    "            cellText=list(zip(*table_data)),\n",
    "            cellLoc='left',\n",
    "            loc='center',\n",
    "        )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.auto_set_column_width(col=list(range(len(table_data))))\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.12)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1650b74-a4db-4440-9b75-411b1c5a0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters_with_table(quant_cluster, player_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8ace2-b3ca-4b45-8058-b1955a0e040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, df in quant_cluster.items():\n",
    "    quant_cluster[pos] = quant_cluster[pos].merge(player_id_mapping, on='player_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bbbd1-9551-4a65-aafb-6118ed7f6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quant_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fa066-0447-4f52-8322-401476712f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"quant_assignments.pkl\", \"wb\") as f:\n",
    "    pickle.dump(quant_cluster, f)\n",
    "\n",
    "quant_cluster_df = pd.concat([df.assign(position=pos) for pos, df in quant_cluster.items()])\n",
    "quant_cluster_df.to_csv(\"quant_assignments_list.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cdf4d7-b318-4579-a4a4-6cd0a84f59ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f7e14-73e9-4089-9117-75bf9a89ae49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299adef-e12d-4e0c-9748-fcec0ede346a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af310e9-345d-488e-b80d-7859b311d934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
