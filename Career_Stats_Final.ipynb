{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c46f2e-eec6-4fff-8f35-2876c778bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import time\n",
    "import random\n",
    "from requests.exceptions import SSLError, ConnectionError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea505c6-a370-4cb6-a16b-546f6f0f2222",
   "metadata": {},
   "source": [
    "# Getting Career Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc04116-df2a-46ab-b7c2-b9bde054f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nfl_draft(year):\n",
    "    url = f\"https://www.pro-football-reference.com/years/{year}/draft.htm\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'drafts'})\n",
    "\n",
    "    rows = table.find('tbody').find_all('tr', class_=lambda x: x != 'thead')\n",
    "    \n",
    "    players_data = []\n",
    "    for row in rows:\n",
    "        try:\n",
    "            pick_cell = row.find('td', {'data-stat': 'draft_pick'})\n",
    "            player_cell = row.find('td', {'data-stat': 'player'})\n",
    "            position_cell = row.find('td', {'data-stat': 'pos'})\n",
    "            team_cell = row.find('td', {'data-stat': 'team'})\n",
    "            college_cell = row.find('td', {'data-stat': 'college_id'})\n",
    "            college_link_cell = row.find('td', {'data-stat': 'college_link'})\n",
    "\n",
    "            if not (player_cell and position_cell and team_cell):\n",
    "                continue\n",
    "\n",
    "            pick = pick_cell.get_text(strip=True) if pick_cell else ''\n",
    "            player_name = player_cell.find('a').text.strip() if player_cell.find('a') else player_cell.text.strip()\n",
    "            player_link = f\"https://www.pro-football-reference.com{player_cell.find('a')['href']}\" if player_cell.find('a') else ''\n",
    "            position = position_cell.get_text(strip=True)\n",
    "            team = team_cell.get_text(strip=True)\n",
    "            college_name = college_cell.find('a').text.strip() if college_cell and college_cell.find('a') else ''\n",
    "            college_stats_link = college_link_cell.find('a')['href'] if college_link_cell and college_link_cell.find('a') else ''\n",
    "\n",
    "            players_data.append({\n",
    "                'Draft Year': year,\n",
    "                'Pick': pick,\n",
    "                'Player Name': player_name,\n",
    "                'Player Link': player_link,\n",
    "                'Position': position,\n",
    "                'Team': team,\n",
    "                'College': college_name,\n",
    "                'College Stats Link': college_stats_link\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(players_data)\n",
    "    return df\n",
    "\n",
    "start_year = 2012\n",
    "end_year = 2021\n",
    "all_years_data = []\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    df_year = scrape_nfl_draft(year)\n",
    "    all_years_data.append(df_year)\n",
    "\n",
    "\n",
    "final_df = pd.concat(all_years_data, ignore_index=True)\n",
    "final_df = final_df[['Draft Year','Pick', 'Team', 'Player Name', 'Player Link', 'Position']]\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409db05-ac65-4bb3-bd7b-f668badad5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_player_stats(player_url, player_position):\n",
    "    response = requests.get(player_url)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Offensive Line\n",
    "    if player_position == 'OL':\n",
    "        combine_div = soup.find('div', {'id': 'div_combine'})\n",
    "        if not combine_div:\n",
    "            comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "            for comment in comments:\n",
    "                if 'div_combine' in comment:\n",
    "                    combine_div = BeautifulSoup(comment, 'html.parser').find('div', {'id': 'div_combine'})\n",
    "                    break\n",
    "\n",
    "        stats_table = combine_div.find('table', {'id': 'combine'}) if combine_div else None\n",
    "        if not stats_table:\n",
    "            print(f'OL table unavaialble for {player_url} so setting to 0')\n",
    "            default_headers = [\n",
    "                'Season', 'Pos', 'Ht', 'Wt', '40yd', 'Bench', 'Broad Jump', \n",
    "                'Shuttle', '3Cone', 'Vertical'\n",
    "            ]\n",
    "            empty_data = {col: 0 for col in default_headers}\n",
    "            return pd.DataFrame([empty_data])\n",
    "\n",
    "        headers = [\n",
    "            'Season', 'Pos', 'Ht', 'Wt', '40yd', 'Bench', 'Broad Jump', \n",
    "            'Shuttle', '3Cone', 'Vertical'\n",
    "        ]\n",
    "        rows = stats_table.find('tbody').find_all('tr')\n",
    "        player_stats = []\n",
    "        for row in rows:\n",
    "            row_data = [td.get_text(strip=True) for td in row.find_all(['th', 'td'])]\n",
    "            if len(row_data) == len(headers):\n",
    "                player_stats.append(row_data)\n",
    "\n",
    "        stats_df = pd.DataFrame(player_stats, columns=headers)\n",
    "        if 'Year' in stats_df.columns:\n",
    "            stats_df.rename(columns={'Year': 'Season'}, inplace=True)\n",
    "        if 'Season' in stats_df.columns:\n",
    "            stats_df = stats_df[stats_df['Season'].str.isdigit()]\n",
    "            stats_df['Season'] = stats_df['Season'].astype(int)\n",
    "\n",
    "        return stats_df\n",
    "\n",
    "\n",
    "    if player_position == 'P':\n",
    "        table_id = 'punting'\n",
    "    elif player_position == 'K':\n",
    "        table_id = 'kicking'\n",
    "    elif player_position == 'QB':\n",
    "        table_id = 'passing'\n",
    "    elif player_position in ['RB', 'FB']:\n",
    "        table_id = 'rushing_and_receiving'\n",
    "    elif player_position in ['WR', 'TE']:\n",
    "        table_id = 'receiving_and_rushing'\n",
    "    elif player_position in ['C', 'T', 'G', 'LS']:\n",
    "        table_id = 'snap_counts'\n",
    "    elif player_position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'OLB', 'ILB', 'S', 'DL']:\n",
    "        table_id = 'defense'\n",
    "    else:\n",
    "        print('Unknown Position')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    stats_table = soup.find('table', {'id': table_id})\n",
    "\n",
    "    \n",
    "    # Fixing case where rushing/receving order in table is flipped\n",
    "    if not stats_table and player_position in ['WR', 'TE']:\n",
    "        print(f'receiving_and_rushing table unavailable for {player_url}. Flipping check')\n",
    "        stats_table = soup.find('table', {'id': 'rushing_and_receiving'})\n",
    "    \n",
    "    if not stats_table and player_position in ['RB', 'FB']:\n",
    "        print(f'rushing_an_receiving table unavailable for {player_url}. Flipping check')\n",
    "        stats_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    # Case where player did not play a snap and doesn't have any statistics\n",
    "    if not stats_table:\n",
    "        print(f'Player has never played a snap and has no statistics. Giving 0 value')\n",
    "        if player_position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'OLB', 'ILB', 'S', 'DL']:\n",
    "            default_headers = [\n",
    "                'Season', 'G', 'GS', 'Int', 'Int Yds', 'IntTD', 'Lng', 'PD', 'FF', 'Fmb', \n",
    "                'FR', 'FR Yds', 'FRTD', 'Sk', 'Comb', 'Solo', 'Ast', 'TFL', 'QBHits', \n",
    "                'Sfty', 'AV', 'Awards'\n",
    "            ]\n",
    "        elif player_position in ['C', 'T', 'G', 'LS']:\n",
    "            default_headers = [\n",
    "                'Season', 'G', 'GS', 'Offense Snaps', 'Offense Pct', 'Defense Snaps', \n",
    "                'Defense Pct', 'Special Teams Snaps', 'Special Teams Pct'\n",
    "            ]\n",
    "        elif player_position == 'P':\n",
    "            default_headers = [\n",
    "                'Season', 'Age', 'Team', 'Lg', 'Pos', 'G', 'GS', 'Pnt', 'Yds', 'Y/P', \n",
    "                'RetYds', 'NetYds', 'NY/P', 'Lng', 'TB', 'TB%', 'Pnt20', 'In20%', 'Blck', \n",
    "                'AV', 'Awards'\n",
    "            ]\n",
    "        elif player_position == 'K':\n",
    "            default_headers = [\n",
    "                'Season', 'Age', 'Team', 'Lg', 'Pos', 'G', 'GS',\n",
    "                'FGA1', 'FGM1', 'FGA2', 'FGM2', 'FGA3', 'FGM3', 'FGA4', 'FGM4', 'FGA5', 'FGM5',\n",
    "                'FGA', 'FGM', 'Lng', 'FG%', 'XPA', 'XPM', 'XP%', \n",
    "                'KO', 'KOYds', 'TB', 'TB%', 'KOAvg', 'AV', 'Awards'\n",
    "            ]\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        empty_data = {col: 0 if col != 'Awards' else '' for col in default_headers}\n",
    "        return pd.DataFrame([empty_data])\n",
    "\n",
    "    # Pulling headers and rows\n",
    "    header_rows = stats_table.find('thead').find_all('tr')\n",
    "    headers_row = header_rows[1] if len(header_rows) > 1 else header_rows[0]\n",
    "    headers = [th.get_text(strip=True) for th in headers_row.find_all('th')]\n",
    "\n",
    "    rows = stats_table.find('tbody').find_all('tr')\n",
    "    player_stats = []\n",
    "    for row in rows:\n",
    "        row_data = [td.get_text(strip=True) for td in row.find_all(['th', 'td'])]\n",
    "        if len(row_data) == len(headers):\n",
    "            player_stats.append(row_data)\n",
    "\n",
    "    stats_df = pd.DataFrame(player_stats, columns=headers)\n",
    "    \n",
    "    if player_position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'OLB', 'ILB', 'S', 'DL']:\n",
    "        yds_columns = [i for i, col in enumerate(stats_df.columns) if col == 'Yds']\n",
    "        if len(yds_columns) > 1:\n",
    "            stats_df.columns.values[yds_columns[0]] = 'Int Yds'\n",
    "            stats_df.columns.values[yds_columns[1]] = 'FR Yds'\n",
    "\n",
    "    # Fixing duplicate column names for offensive positions\n",
    "    if player_position in ['WR', 'TE']:\n",
    "        first_is_rush = True\n",
    "    elif player_position in ['RB', 'FB']:\n",
    "        first_is_rush = False\n",
    "    else:\n",
    "        first_is_rush = None\n",
    "\n",
    "    if first_is_rush is not None:\n",
    "        renaming_map = {\n",
    "            'Yds': 'Rec Yds' if first_is_rush else 'Rush Yds',\n",
    "            'TD': 'Rec TD' if first_is_rush else 'Rush TD',\n",
    "            '1D': 'Rec 1D' if first_is_rush else 'Rush 1D',\n",
    "            'Lng': 'Rec Lng' if first_is_rush else 'Rush Lng',\n",
    "            'Succ%': 'Rec Succ%' if first_is_rush else 'Rush Succ%',\n",
    "            'Y/G': 'Rec Y/G' if first_is_rush else 'Rush Y/G'\n",
    "        }\n",
    "        for key, new_value in renaming_map.items():\n",
    "            cols = [i for i, col in enumerate(stats_df.columns) if col == key]\n",
    "            if len(cols) > 1:\n",
    "                stats_df.columns.values[cols[0]] = new_value\n",
    "                stats_df.columns.values[cols[1]] = 'Rush '+ key if first_is_rush else 'Rec ' + key\n",
    "\n",
    "    # fixing duplicate column names for kicker\n",
    "    if player_position == 'K':\n",
    "        fga_cols = [i for i, col in enumerate(stats_df.columns) if col == 'FGA']\n",
    "        fgm_cols = [i for i, col in enumerate(stats_df.columns) if col == 'FGM']\n",
    "\n",
    "        if len(fga_cols) > 1:\n",
    "            stats_df.columns.values[fga_cols[0]] = '0-19 FGA'\n",
    "            stats_df.columns.values[fga_cols[1]] = '20-29 FGA'\n",
    "            stats_df.columns.values[fga_cols[2]] = '30-39 FGA'\n",
    "            stats_df.columns.values[fga_cols[3]] = '40-49 FGA'\n",
    "            stats_df.columns.values[fga_cols[4]] = '50+ FGA'\n",
    "            stats_df.columns.values[fga_cols[5]] = 'Total FGA'\n",
    "        if len(fgm_cols) > 1:\n",
    "            stats_df.columns.values[fgm_cols[0]] = '0-19 FGM'\n",
    "            stats_df.columns.values[fgm_cols[1]] = '20-29 FGM'\n",
    "            stats_df.columns.values[fgm_cols[2]] = '30-39 FGM'\n",
    "            stats_df.columns.values[fgm_cols[3]] = '40-49 FGM'\n",
    "            stats_df.columns.values[fgm_cols[4]] = '50+ FGM'\n",
    "            stats_df.columns.values[fgm_cols[5]] = 'Total FGM'\n",
    "\n",
    "    if player_position in ['C', 'T', 'G', 'LS']:\n",
    "        stats_df.rename(columns={'Year': 'Season'}, inplace=True)\n",
    "        rename_map = {\n",
    "            'Num': ['Offense Snaps', 'Defense Snaps', 'Special Teams Snaps'],\n",
    "            \"Pct\": ['Offense Pct', 'Defense Pct', 'Special Teams Pct']\n",
    "        }\n",
    "        num_columns = [i for i, col in enumerate(stats_df.columns) if col == 'Num']\n",
    "        pct_columns = [i for i, col in enumerate(stats_df.columns) if col == 'Pct']\n",
    "\n",
    "        if len(num_columns) == 3:\n",
    "            stats_df.columns.values[num_columns[0]] = rename_map['Num'][0]\n",
    "            stats_df.columns.values[num_columns[1]] = rename_map['Num'][1]\n",
    "            stats_df.columns.values[num_columns[2]] = rename_map['Num'][2]\n",
    "\n",
    "        if len(pct_columns) == 3:\n",
    "            stats_df.columns.values[pct_columns[0]] = rename_map['Pct'][0]\n",
    "            stats_df.columns.values[pct_columns[1]] = rename_map['Pct'][1]\n",
    "            stats_df.columns.values[pct_columns[2]] = rename_map['Pct'][2]\n",
    "\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc8bde-226a-4145-86ef-a2e78e2f46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One player at a time\n",
    "player_index = 929 \n",
    "row = final_df.iloc[player_index]\n",
    "\n",
    "player_url = row['Player Link']\n",
    "player_position = row['Position']\n",
    "\n",
    "if player_url:\n",
    "    print(f\"Scraping stats for {row['Player Name']} ({player_position}) from {player_url}...\")\n",
    "    player_data = scrape_player_stats(player_url, player_position)\n",
    "\n",
    "stat = player_data\n",
    "print(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac43410-d9d1-45f0-87d1-c88e4b6ef205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_qb_data(qb_stats_df, start_season):\n",
    "    \n",
    "    if qb_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    qb_stats_df['Season'] = pd.to_numeric(qb_stats_df['Season'], errors='coerce')\n",
    "\n",
    "    filtered_df = qb_stats_df.drop_duplicates(subset=['Season').copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, 'Season')\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f'No data available for first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    # renaming duplicate columns\n",
    "    yds_columns = [i for i, col in enumerate(filtered_df.columns) if col == 'Yds']\n",
    "    if len(yds_columns) > 1:\n",
    "        filtered_df.columns.values[yds_columns[0]] = 'Pass Yds'\n",
    "        filtered_df.columns.values[yds_columns[1]] = 'Sack Yds'\n",
    "\n",
    "    # Breaking record for Wins-Losses-Draws to Win, Losses, Draw\n",
    "    if 'QBrec' in filtered_df.columns:\n",
    "        qb_record_split = filtered_df['QBrec'].astype(str).str.split('-', expand=True)\n",
    "        filtered_df['Wins'] = pd.to_numeric(qb_record_split[0], errors='coerce').fillna(0).astype(float)\n",
    "        filtered_df['Losses'] = pd.to_numeric(qb_record_split[1], errors='coerce').fillna(0).astype(float)\n",
    "        filtered_df['Draws'] = pd.to_numeric(qb_record_split[2], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "    numeric_columns = [\n",
    "    'G', 'GS', 'Wins', 'Losses', 'Draws', 'Cmp', 'Att', 'Cmp%', 'Pass Yds', 'TD', 'TD%', 'Int',\n",
    "    '1D', 'Succ%', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'Sk', 'Sack Yds', 'Sk%', 'NY/A', 'ANY/A',\n",
    "    '4QC', 'GWD', 'AV'\n",
    "    ]\n",
    "\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col not in filtered_df.columns:\n",
    "            filtered_df[col] = 0.0\n",
    "            \n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "    if 'Lng' in filtered_df.columns:\n",
    "        filtered_df.drop(columns=['Lng'], inplace=True)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 if col != 'Awards' else '' for col in filtered_df.columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "\n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        **{col: 'sum' for col in numeric_columns \n",
    "           if col not in ['Cmp%', 'TD%', 'Succ%', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'Sk%', 'NY/A', 'ANY/A']},\n",
    "\n",
    "        **{col: 'mean' for col in ['Cmp%', 'TD%', 'Succ%', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'Sk%', 'NY/A', 'ANY/A']},\n",
    "\n",
    "        'Awards': lambda x: ', '.join(x.dropna()) if 'Awards' in filtered_df.columns else ''\n",
    "    }\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a357a5-e716-4489-8b21-717070ccbcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_offense_data(offense_stats_df, start_season):\n",
    "\n",
    "    if offense_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    offense_stats_df['Season'] = pd.to_numeric(offense_stats_df['Season'], errors='coerce')\n",
    "\n",
    "    filtered_df = offense_stats_df.drop_duplicates(subset=['Season']).copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, 'Season')\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f'No available data for the first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    numeric_columns = [\n",
    "        'G', 'GS', 'Att', 'Rush Yds', 'Rush TD', 'Rush 1D', 'Tgt', 'Rec', 'Rec Yds',\n",
    "        'Rec TD', 'Rec 1D', 'Touch', 'YScm', 'RRTD', 'Fmb', 'AV',\n",
    "        'Rush Succ%', 'Y/A', 'Rush Y/G', 'A/G', 'Y/R', 'Rec Succ%', 'R/G',\n",
    "        'Rec Y/G', 'Ctch%', 'Y/Tgt', 'Y/Tch'\n",
    "    ]\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col not in filtered_df.columns:\n",
    "            filtered_df[col] = 0.0 \n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "    for col in ['Rush Lng', 'Rec Lng']:\n",
    "        if col in filtered_df.columns:\n",
    "            filtered_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 if col != 'Awards' else '' for col in filtered_df.columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "    \n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "\n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        **{col: 'sum' for col in numeric_columns \n",
    "           if col not in ['Rush Succ%', 'Y/A', 'Rush Y/G', 'A/G', 'Y/R', 'Rec Succ%', 'R/G', 'Rec Y/G', 'Ctch%', 'Y/Tgt', 'Y/Tch']},\n",
    "        \n",
    "        **{col: 'mean' for col in ['Rush Succ%', 'Y/A', 'Rush Y/G', 'A/G', 'Y/R', 'Rec Succ%', 'R/G', 'Rec Y/G', 'Ctch%', 'Y/Tgt', 'Y/Tch']},\n",
    "\n",
    "        'Awards': lambda x: ', '.join(map(str, x.dropna().unique())) if 'Awards' in filtered_df.columns else ''\n",
    "    }\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d08b2c-f050-4fc0-9daa-549a451a0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_defense_data(defense_stats_df, start_season):\n",
    "    \n",
    "    if defense_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    defense_stats_df['Season'] = pd.to_numeric(defense_stats_df['Season'], errors=\"coerce\")\n",
    "\n",
    "    filtered_df = defense_stats_df.drop_duplicates(subset=['Season']).copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, 'Season')\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f'No available data for the first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    numeric_columns = [\n",
    "        'G', 'GS', 'Int', 'Int Yds', 'IntTD', 'PD', 'FF', 'Fmb',\n",
    "        'FR', 'FR Yds', 'FRTD', 'Sk', 'Comb', 'Solo', 'Ast', 'TFL',\n",
    "        'QBHits', 'Sfty', 'AV'\n",
    "    ]\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col not in filtered_df.columns:\n",
    "            filtered_df[col] = 0.0 \n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "    if 'Lng' in filtered_df.columns:\n",
    "        filtered_df.drop(columns=['Lng'], inplace=True)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 if col != 'Awards' else '' for col in filtered_df.columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "\n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "\n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        **{col: 'sum' for col in numeric_columns},\n",
    "        \n",
    "        'Awards': lambda x: ', '.join(map(str, x.dropna().unique())) if 'Awards' in filtered_df.columns else ''\n",
    "    }\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d402cf8-e8eb-4225-bf00-5b4c2dc90d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_center_data(center_stats_df, start_season):\n",
    "\n",
    "    if center_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    center_stats_df['Season'] = pd.to_numeric(center_stats_df['Season'], errors='coerce')\n",
    "\n",
    "    filtered_df = center_stats_df.drop_duplicates(subset=['Season']).copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, 'Season')\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f'No available data for the first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # removing % from string columns to turn to floats\n",
    "    pct_columns = ['Offense Pct', 'Defense Pct', 'Special Teams Pct']\n",
    "    for col in pct_columns:\n",
    "        if col in filtered_df.columns:\n",
    "            filtered_df[col] = (\n",
    "                filtered_df[col]\n",
    "                .astype(str)\n",
    "                .str.replace('%', '', regex=False)\n",
    "                .replace('', '0')\n",
    "                .astype(float)\n",
    "                .fillna(0.0)\n",
    "            )\n",
    "\n",
    "    numeric_columns = [\n",
    "        'G', 'GS', 'Offense Snaps', 'Offense Pct', 'Defense Snaps',\n",
    "        'Defense Pct', 'Special Teams Snaps', 'Special Teams Pct'\n",
    "    ]\n",
    "\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in filtered_df.columns:\n",
    "            filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce').fillna(0).astype(float)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 if col != 'Awards' else '' for col in filtered_df.columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "\n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "    \n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        \"G\": \"sum\",\n",
    "        \"GS\": \"sum\",\n",
    "        \"Offense Snaps\": \"sum\",\n",
    "        \"Defense Snaps\": \"sum\",\n",
    "        \"Special Teams Snaps\": \"sum\",\n",
    "        \"Offense Pct\": \"mean\",\n",
    "        \"Defense Pct\": \"mean\",\n",
    "        \"Special Teams Pct\": \"mean\"\n",
    "    }\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef1a740-3459-497d-b959-049d39835be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_punting_data(punting_stats_df, start_season):\n",
    "    \n",
    "    if punting_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    punting_stats_df['Season'] = pd.to_numeric(punting_stats_df['Season'], errors='coerce')\n",
    "\n",
    "    filtered_df = punting_stats_df.drop_duplicates(subset=['Season']).copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, \"Season\")\n",
    "\n",
    "    if filtered_df.empty:\n",
    "    print(f'No available data for the first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    numeric_columns = [\n",
    "        'G', 'GS', 'Pnt', 'Yds', 'Y/P', 'RetYds', 'NetYds', 'NY/P',\n",
    "        'Lng', 'TB', 'TB%', 'Pnt20', 'In20%', 'Blck', 'AV'\n",
    "    ]\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col not in filtered_df.columns:\n",
    "            filtered_df[col] = 0.0\n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors=\"coerce\").fillna(0).astype(float)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 for col in numeric_columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "        if 'Awards' in filtered_df.columns:\n",
    "            empty_row['Awards'] = ''\n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "\n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        **{col: \"sum\" for col in numeric_columns if col not in [\"Y/P\", \"NY/P\", \"TB%\", \"In20%\"]},\n",
    "\n",
    "        **{col: \"mean\" for col in [\"Y/P\", \"NY/P\", \"TB%\", \"In20%\"]},\n",
    "    }\n",
    "\n",
    "    if 'Awards' in filtered_df.columns:\n",
    "        agg_methods['Awards'] = lambda x: ', '.join(map(str, x.dropna().unique()))\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41014e9e-4389-41f0-b811-2ca9ac0661ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_kicking_data(kicking_stats_df, start_season):\n",
    "\n",
    "    if kicking_stats_df.empty:\n",
    "        print(f'No data available')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    kicking_stats_df['Season'] = pd.to_numeric(kicking_stats_df['Season'], errors='coerce')\n",
    "\n",
    "    filtered_df = kicking_stats_df.drop_duplicates(subset=['Season']).copy()\n",
    "\n",
    "    # first 4 seasons\n",
    "    filtered_df = filtered_df.nsmallest(4, \"Season\")\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(f'No available data for the first 4 seasons')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    numeric_columns = [\n",
    "        'G', 'GS', '0-19 FGA', '0-19 FGM', '20-29 FGA', '20-29 FGM',\n",
    "        '30-39 FGA', '30-39 FGM', '40-49 FGA', '40-49 FGM', '50+ FGA', '50+ FGM',\n",
    "        'Total FGA', 'Total FGM', 'Lng', 'FG%', 'XPA', 'XPM', 'XP%',\n",
    "        'KO', 'KOYds', 'TB', 'TB%', 'KOAvg', 'AV'\n",
    "    ]\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col not in filtered_df.columns:\n",
    "            filtered_df[col] = 0.0\n",
    "        filtered_df[col] = pd.to_numeric(filtered_df[col], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "\n",
    "    # making sure we have at least 4 seasons and if not filling values with 0 \n",
    "    while len(filtered_df) < 4:\n",
    "        missing_season = filtered_df['Season'].max() + 1 if not filtered_df.empty else start_season\n",
    "        empty_row = {col: 0.0 for col in numeric_columns}\n",
    "        empty_row['Season'] = missing_season\n",
    "        empty_row['Awards'] = ''\n",
    "        filtered_df = pd.concat([filtered_df, pd.DataFrame([empty_row])], ignore_index=True)\n",
    "        \n",
    "    # Aggreagating stats\n",
    "    agg_methods = {\n",
    "        **{col: 'sum' for col in numeric_columns if col not in ['FG%', 'XP%', 'TB%', 'KOAvg']},\n",
    "\n",
    "        **{col: 'mean' for col in ['FG%', 'XP%', 'TB%', 'KOAvg']},\n",
    "\n",
    "        'Awards': lambda x: ', '.join(map(str, x.dropna().unique())) if 'Awards' in filtered_df.columns else ''\n",
    "    }\n",
    "\n",
    "    aggregated_stats = filtered_df.agg(agg_methods).to_frame().T\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        if col in aggregated_stats.columns:\n",
    "            aggregated_stats[col] = aggregated_stats[col].astype(float)\n",
    "\n",
    "    aggregated_stats.insert(0, 'Start Season', start_season)\n",
    "\n",
    "    return aggregated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c636561-1ebb-4f16-84b1-1cbea489852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_player_data(stats_df, player_position):\n",
    "\n",
    "    position = player_position\n",
    "    start_season = stats_df['Season'].iloc[0]\n",
    "    if position == 'QB':\n",
    "        return process_qb_data(stats_df, start_season)\n",
    "    elif position in ['RB', 'WR', 'TE', 'FB']:\n",
    "        return process_offense_data(stats_df, start_season)\n",
    "    elif position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'OLB', 'ILB', 'S', 'DL']:\n",
    "        return process_defense_data(stats_df, start_season)\n",
    "    elif position in ['C', 'T', 'G', 'LS']:\n",
    "        return process_center_data(stats_df, start_season)\n",
    "    elif position == 'OL':\n",
    "        return stats_df\n",
    "    elif position == 'P':\n",
    "        return process_punting_data(stats_df, start_season)\n",
    "    elif position == 'K':\n",
    "        return process_kicking_data(stats_df, start_season)\n",
    "    else:\n",
    "        print(f'Unknown position')\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42d18b-6d82-46cd-b401-a34734e958e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = process_player_data(stat, player_position)\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6f5951-c7c1-49df-8cd3-f8d9a6fedd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_with_adaptive_delay(url, base_delay_range=(3, 7), request_counter=[0], adaptive_delay=[3]):\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # waiting before immediately sending request\n",
    "            current_delay = adaptive_delay[0] + random.uniform(*base_delay_range)\n",
    "            time.sleep(current_delay)\n",
    "\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                request_counter[0] += 1\n",
    "                if request_counter[0] % 10 == 0:\n",
    "                    # delay\n",
    "                    time.sleep(random.uniform(10, 20))  \n",
    "                return response\n",
    "\n",
    "            elif response.status_code == 429:\n",
    "                retry_after = int(response.headers.get('Retry-After', adaptive_delay[0] * 2))\n",
    "                print(f'Blocked by rate limit. Retrying in {retry_after} seconds')\n",
    "                adaptive_delay[0] *= 2\n",
    "                time.sleep(retry_after)\n",
    "\n",
    "            else:\n",
    "                print(f\"Request failed. Attempting again\")\n",
    "                attempt += 1\n",
    "\n",
    "        except (SSLError, ConnectionError) as e:\n",
    "            print(f'Retrying with next attempt having a longer delay')\n",
    "            adaptive_delay[0] *= 2\n",
    "            time.sleep(adaptive_delay[0])\n",
    "            attempt += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2df76-6af3-43ce-bbfc-807009ce0b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "request_counter = [0]\n",
    "adaptive_delay = [3]\n",
    "\n",
    "qb_data = []\n",
    "offense_data = []\n",
    "defense_data = []\n",
    "center_data = []\n",
    "ol_data = []\n",
    "punting_data = []\n",
    "kicking_data = []\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    player_url = row['Player Link']\n",
    "    player_pick = row['Pick']\n",
    "    player_position = row['Position']\n",
    "    player_name = row['Player Name'] \n",
    "    player_team = row['Team'] \n",
    "\n",
    "\n",
    "    start_season = row[\"Draft Year\"]\n",
    "\n",
    "    if player_url:\n",
    "        print(f'Scraping stats for {player_name} ({player_position}) from {player_url}')\n",
    "\n",
    "        response = fetch_with_adaptive_delay(player_url, request_counter=request_counter, adaptive_delay=adaptive_delay)\n",
    "\n",
    "        if response is not None:\n",
    "            player_data = scrape_player_stats(player_url, player_position)\n",
    "\n",
    "            if not player_data.empty:\n",
    "                if player_position == 'QB':\n",
    "                    processed_row = process_qb_data(player_data, start_season)\n",
    "                elif player_position in ['RB', 'WR', 'TE', 'FB']:\n",
    "                    processed_row = process_offense_data(player_data, start_season)\n",
    "                elif player_position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'OLB', 'ILB', 'S', 'DL']:\n",
    "                    processed_row = process_defense_data(player_data, start_season)\n",
    "                elif player_position in ['C', 'T', 'G', 'LS']:\n",
    "                    processed_row = process_center_data(player_data, start_season)\n",
    "                elif player_position == 'OL':\n",
    "                    processed_row = player_data  # No processing function, just storing raw data\n",
    "                elif player_position == 'P':\n",
    "                    processed_row = process_punting_data(player_data, start_season)\n",
    "                elif player_position =='K':\n",
    "                    processed_row = process_kicking_data(player_data, start_season)\n",
    "                else:\n",
    "                    continue \n",
    "\n",
    "                processed_row = processed_row.to_frame().T\n",
    "\n",
    "                processed_row.insert(0, 'Player Name', player_name)\n",
    "                processed_row.insert(1, 'Pick', player_pick)\n",
    "                processed_row.insert(2, 'Position', player_position)\n",
    "                processed_row.insert(3, 'Team', player_team)\n",
    "                processed_row.insert(4, 'Draft Year', start_season)\n",
    "\n",
    "                if player_position == 'QB':\n",
    "                    qb_data.append(processed_row)\n",
    "                elif player_position in ['RB', 'WR', 'TE', 'FB']:\n",
    "                    offense_data.append(processed_row)\n",
    "                elif player_position in ['DB', 'LB', 'DE', 'DT', 'NT', 'CB', 'DL', 'OLB', 'ILB', 'S']:\n",
    "                    defense_data.append(processed_row)\n",
    "                elif player_position in ['C', 'T', 'G', 'LS']:\n",
    "                    center_data.append(processed_row)\n",
    "                elif player_position == 'OL':\n",
    "                    ol_data.append(processed_row)\n",
    "                elif player_position == 'P':\n",
    "                    punting_data.append(processed_row)\n",
    "                elif player_position == 'K':\n",
    "                    kicking_data.append(processed_row)\n",
    "\n",
    "qb_df = pd.concat(qb_data, ignore_index=True) if qb_data else pd.DataFrame()\n",
    "offense_df = pd.concat(offense_data, ignore_index=True) if offense_data else pd.DataFrame()\n",
    "defense_df = pd.concat(defense_data, ignore_index=True) if defense_data else pd.DataFrame()\n",
    "center_df = pd.concat(center_data, ignore_index=True) if center_data else pd.DataFrame()\n",
    "ol_df = pd.concat(ol_data, ignore_index=True) if ol_data else pd.DataFrame()\n",
    "punting_df = pd.concat(punting_data, ignore_index=True) if punting_data else pd.DataFrame()\n",
    "kicking_df = pd.concat(kicking_data, ignore_index=True) if kicking_data else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe87aa-daf1-4aaf-b17e-87c27b94f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(center_df['Position'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41227c43-d181-40f3-8127-2732921b2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_awards(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['Awards List'] = df['Awards'].apply(lambda x: [award.strip() for award in x.split(',')] if x else [])\n",
    "\n",
    "    all_awards = set()\n",
    "    for awards in df['Awards List']:\n",
    "        all_awards.update(awards)\n",
    "\n",
    "    all_awards.discard('')\n",
    "\n",
    "    for award in all_awards:\n",
    "        df[award] = df['Awards List'].apply(lambda x: x.count(award))\n",
    "\n",
    "    df.drop(columns=[\"Awards List\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7971548-6de6-4e35-b639-9b2f4c2d2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_df = process_awards(qb_df)\n",
    "offense_df = process_awards(offense_df)\n",
    "defense_df = process_awards(defense_df)\n",
    "punting_df = process_awards(punting_df)\n",
    "kicking_df = process_awards(kicking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99670227-2fd8-4b37-839f-87189c4a96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_df.to_csv('qb_career.csv')\n",
    "offense_df.to_csv('offense_career.csv')\n",
    "defense_df.to_csv('defense_career.csv')\n",
    "center_df.to_csv('center_career.csv')\n",
    "ol_df.to_csv('ol_career.csv')\n",
    "punting_df.to_csv('punting_career.csv')\n",
    "kicking_df.to_csv('kicking_career.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cf910-562f-49a0-8401-07f02247ad19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370bb6e-3f36-4c9a-bf8e-62bdaf7d8072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01823bdc-afbd-4320-97df-6fc79aaa63c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
