{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0d4bd-35a1-4c29-9c53-4b3c58b2239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from kneed import KneeLocator\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08965dc-4e1c-4de9-a2b6-d48238ef9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_map = pd.read_csv('quant_map.csv')\n",
    "\n",
    "quant_map_loaded = {key: group.drop(columns=['key']) for key, group in quant_map.groupby('key')}\n",
    "\n",
    "noise_map = quant_map_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc7362-3f5c-4c34-b7f8-8bf68f5eaf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id_mapping = pd.read_csv(\"player_id_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1edb67-2501-4e82-a420-1dba615b5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = ['Playing Ability','Competitive', 'Character', 'Team Player', 'Leadership', 'Passion', \n",
    "                    'Body Language', 'Selfless', 'Low Ego', 'Loyalty', 'Teamwork', 'Trustworthy', 'Dependable', 'Integrity', 'Honest',\n",
    "                   'Maturity', 'Responsible', 'Positive', 'Confident', 'Adaptive', 'Work Ethic', 'Driven', 'Resilient', 'Effort']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98643c83-ad21-4dd0-8ee4-31fe6d39b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, df in noise_map.items():\n",
    "    n_rows = len(df)\n",
    "    n_noise = len(candidate_labels)\n",
    "    \n",
    "    noise_matrix = np.random.uniform(low=-1.0, high=1.0, size=(n_rows, n_noise))\n",
    "\n",
    "    noise_cols = [f\"noise_{label}\" for label in candidate_labels]\n",
    "    \n",
    "    for i, col_name in enumerate(noise_cols):\n",
    "        df[col_name] = noise_matrix[:, i]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df[noise_cols] = scaler.fit_transform(df[noise_cols])\n",
    "    \n",
    "    noise_map[position] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c623644-e804-43e8-81dd-85945fc23c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(lib, candidate_labels, top_n=5, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    feature_selected_lib = {}\n",
    "\n",
    "    noise_labels = [f\"noise_{label}\" for label in candidate_labels]\n",
    "\n",
    "    for pos, value in lib.items():\n",
    "        df = value['DataFrame']\n",
    "\n",
    "        player_ids = df['player_id']\n",
    "\n",
    "        preserved_noise_features = df[noise_labels] if all(label in df.columns for label in noise_labels) else None\n",
    "\n",
    "        df_no_labels = df.drop(columns=candidate_labels + noise_labels, errors='ignore')\n",
    "        df_no_id = df_no_labels.drop(columns=['player_id'], errors='ignore')\n",
    "\n",
    "        df_no_id = df_no_id.drop(columns=['cluster'], errors='ignore')\n",
    "\n",
    "\n",
    "        random_labels = np.random.randint(0, 2, size=len(df_no_id))\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
    "        rf.fit(df_no_id, random_labels)\n",
    "        feature_importances = rf.feature_importances_\n",
    "\n",
    "        importance_df = pd.DataFrame({'Feature': df_no_id.columns, 'Importance': feature_importances})\n",
    "        importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "        selected_features = importance_df[\"Feature\"][:top_n].tolist()\n",
    "\n",
    "        df_selected = df[selected_features].copy()\n",
    "        df_selected[\"player_id\"] = player_ids\n",
    "\n",
    "        if preserved_noise_features is not None:\n",
    "            for label in noise_labels:\n",
    "                if label in df.columns:\n",
    "                    df_selected[label] = df[label]\n",
    "\n",
    "        feature_selected_lib[pos] = {'DataFrame': df_selected, 'Optimal_k': value['Optimal_k']}\n",
    "\n",
    "        print(f\"Position: {pos} - Selected Features: {selected_features + noise_labels}\")\n",
    "\n",
    "    return feature_selected_lib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f897269-f281-4468-9fb2-31081d820a22",
   "metadata": {},
   "source": [
    "# Open Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e3bd55-2e9f-4c69-abf2-137690c308ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(lib, candidate_labels, top_n=2, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    feature_selected_lib = {}\n",
    "\n",
    "    noise_labels = [f\"noise_{label}\" for label in candidate_labels]\n",
    "\n",
    "    for pos, value in lib.items():\n",
    "        df = value['DataFrame']\n",
    "\n",
    "        player_ids = df['player_id']\n",
    "\n",
    "        df_no_id = df.drop(columns=['player_id', 'cluster'], errors='ignore')\n",
    "\n",
    "        random_labels = np.random.randint(0, 2, size=len(df_no_id))\n",
    "\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=random_seed)\n",
    "        rf.fit(df_no_id, random_labels)\n",
    "        feature_importances = rf.feature_importances_\n",
    "        importance_df = pd.DataFrame({'Feature': df_no_id.columns, 'Importance': feature_importances})\n",
    "        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "        selected_features = importance_df['Feature'][:top_n].tolist()\n",
    "\n",
    "        df_selected = df[selected_features].copy()\n",
    "        df_selected['player_id'] = player_ids\n",
    "\n",
    "        feature_selected_lib[pos] = {'DataFrame': df_selected, 'Optimal_k': value['Optimal_k']}\n",
    "\n",
    "        print(f\"Position: {pos} - Selected Features: {selected_features}\")\n",
    "\n",
    "    return feature_selected_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a54801-59d8-495e-9aa4-c8cac6e7b49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_elbow(pos_mapping):\n",
    "    def elbow(df, name, ax):\n",
    "        player_ids = df['player_id']\n",
    "        df_no_id = df.drop(columns=['player_id'])\n",
    "\n",
    "        inertias = []\n",
    "        cluster_range = range(2, min(len(df_no_id), 15))\n",
    "        \n",
    "        for k in cluster_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(df_no_id)  \n",
    "            inertias.append(kmeans.inertia_)\n",
    "\n",
    "        knee_locator = KneeLocator(cluster_range, inertias, curve='convex', direction='decreasing')\n",
    "        optimal_k = knee_locator.knee\n",
    "\n",
    "        # if no optimal k set to 3\n",
    "        if optimal_k is None:\n",
    "            optimal_k = 3\n",
    "\n",
    "        # Plot Elbow Method on the provided axis (ax)\n",
    "        ax.plot(cluster_range, inertias, marker='o')\n",
    "        ax.axvline(x=optimal_k, color=\"r\", linestyle=\"--\", label=f\"Optimal k={optimal_k}\")\n",
    "        ax.set_title(f'Elbow Method {name}')\n",
    "        ax.set_xlabel('Number of Clusters')\n",
    "        ax.set_ylabel('Inertia')\n",
    "        ax.legend()\n",
    "    \n",
    "        return optimal_k, player_ids\n",
    "\n",
    "    quantitative = {}\n",
    "    \n",
    "    num_positions = len(pos_mapping)\n",
    "    rows = (num_positions // 3) + 1\n",
    "    cols = 3\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (pos, df) in enumerate(pos_mapping.items()):\n",
    "        opt_k, player_ids = elbow(df, pos, axes[i])\n",
    "        df['player_id'] = player_ids  \n",
    "        quantitative[pos] = {'DataFrame': df, 'Optimal_k': opt_k}\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return quantitative\n",
    "\n",
    "noise = get_elbow(noise_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7aae7b-a2ee-4015-a495-2bfad3a008bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_noise = select_important_features(noise, candidate_labels, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b56446c-a6f4-4d6e-9248-3b5e24ce4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(lib):\n",
    "    def evaluate_kmeans(params, data):\n",
    "        model = KMeans(**params)\n",
    "        labels = model.fit_predict(data)\n",
    "        score = silhouette_score(data, labels)\n",
    "        return score\n",
    "\n",
    "    for pos, value in lib.items():\n",
    "        df = value['DataFrame']\n",
    "        k = value['Optimal_k']\n",
    "\n",
    "        player_ids = df['player_id']\n",
    "        df_no_id = df.drop(columns=['player_id'])  \n",
    "\n",
    "        param_grid = {\n",
    "            'n_clusters': [k],\n",
    "            'init': ['k-means++', 'random'],\n",
    "            'max_iter': [50, 100, 300], \n",
    "            'random_state': [42]\n",
    "        }\n",
    "\n",
    "        param_grid = ParameterGrid(param_grid)\n",
    "        best_params = None\n",
    "        best_score = -1\n",
    "\n",
    "        for params in param_grid:\n",
    "            score = evaluate_kmeans(params, df_no_id)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_params = params\n",
    "\n",
    "        optimal_kmeans = KMeans(**best_params)\n",
    "        cluster_labels = optimal_kmeans.fit_predict(df_no_id)\n",
    "\n",
    "        df['cluster'] = cluster_labels.astype(str)\n",
    "        df['player_id'] = player_ids  \n",
    "\n",
    "        lib[pos]['DataFrame'] = df\n",
    "\n",
    "    return {pos: info['DataFrame'] for pos, info in lib.items()}\n",
    "\n",
    "noise_clustering= clustering(filtered_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd3d15-7a2b-4fa7-860f-9169cb369732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters_with_table(qualitative, player_id_mapping):\n",
    "    for pos, df in qualitative.items():\n",
    "        df = df.reset_index()\n",
    "        df = df.merge(player_id_mapping, on='player_id', how='left')\n",
    "\n",
    "        df['cluster'] = df['cluster'].astype(int)\n",
    "        df['cluster'] = pd.Categorical(df['cluster'], categories=sorted(df['cluster'].unique()), ordered=True)\n",
    "\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_features = pca.fit_transform(\n",
    "            df.drop(columns=['cluster', 'player_name', 'pos_abbr', 'player_id'], errors='ignore')\n",
    "        )\n",
    "\n",
    "        df['PCA1'] = pca_features[:, 0]\n",
    "        df['PCA2'] = pca_features[:, 1]\n",
    "\n",
    "        sorted_clusters = sorted(df['cluster'].unique())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        scatter_plot = sns.scatterplot(\n",
    "            data=df,\n",
    "            x='PCA1',\n",
    "            y='PCA2',\n",
    "            hue='cluster',\n",
    "            palette='viridis',\n",
    "            s=100,\n",
    "            alpha=0.7,\n",
    "            hue_order=sorted_clusters\n",
    "        )\n",
    "        plt.title(f'Cluster Visualization of {pos} (PCA)', fontsize=16)\n",
    "        plt.xlabel('PCA Component 1')\n",
    "        plt.ylabel('PCA Component 2')\n",
    "        plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "        cluster_info = []\n",
    "        grouped = df.groupby('cluster', observed=True)\n",
    "        for cluster, group in grouped:\n",
    "            cluster_text = [f\"Cluster {cluster}\"] + [f\"{row['player_name']} ({row['pos_abbr']})\" for _, row in group.iterrows()]\n",
    "            cluster_info.append(cluster_text)\n",
    "\n",
    "        max_rows_per_column = 20\n",
    "        flattened_table = []\n",
    "        for cluster_text in cluster_info:\n",
    "            flattened_table.extend(cluster_text)\n",
    "            flattened_table.append('')\n",
    "\n",
    "        num_columns = math.ceil(len(flattened_table) / max_rows_per_column)\n",
    "        table_data = [\n",
    "            flattened_table[i * max_rows_per_column:(i + 1) * max_rows_per_column]\n",
    "            for i in range(num_columns)\n",
    "        ]\n",
    "\n",
    "        max_col_length = max(len(column) for column in table_data)\n",
    "        table_data = [\n",
    "            column + [''] * (max_col_length - len(column)) for column in table_data\n",
    "        ]\n",
    "\n",
    "        table_ax = plt.gcf().add_axes([0.1, -0.4, 0.8, 0.3])\n",
    "        table_ax.axis('off')\n",
    "        table = table_ax.table(\n",
    "            cellText=list(zip(*table_data)),\n",
    "            cellLoc='left',\n",
    "            loc='center',\n",
    "        )\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(10)\n",
    "        table.auto_set_column_width(col=list(range(len(table_data))))\n",
    "\n",
    "        plt.subplots_adjust(bottom=0.12)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448016bf-c40c-4388-a397-1a77d96ad1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters_with_table(noise_clustering, player_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2eca9-0202-4178-8a58-8facb2ddb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos, df in noise_clustering.items():\n",
    "    noise_clustering[pos] = noise_clustering[pos].merge(player_id_mapping, on='player_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6dd88-da55-46a3-abc3-d40be83191d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_cluster_df = pd.concat([df.assign(position=pos) for pos, df in noise_clustering.items()])\n",
    "noise_cluster_df = noise_cluster_df[['player_id', 'cluster', 'position', 'draft_year', 'player_name']]\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "noise_cluster_df.to_csv('noise_assignment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003237b-1307-4ef4-a758-48a888758fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e3b5b-edd9-412e-8eb0-2bc46d62f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24404b-f5ea-4601-8568-b30761938085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
