{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36acc7a-6563-4321-b7d7-12e895610cf0",
   "metadata": {},
   "source": [
    "# Regresison Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408aeb76-c178-4111-9fe0-8ad2e8dde5fe",
   "metadata": {},
   "source": [
    "# Generalizing Case for multiple positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc2bb7-f164-4ba4-92a5-841942d95af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39228634-1cc6-4a35-8252-d799a8019bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative_displacement_positions = ['QB','DT','FB','LB','OG','DE','WR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94017efe-65fc-4ede-a56e-1ebbe0abd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('quant_assignments.pkl', 'rb') as f:\n",
    "    quant_clusters = pickle.load(f)\n",
    "    \n",
    "print(quant_clusters['WR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43330b8-bdc5-49fd-a058-d810c79575b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match(row, df_to_match, column_name):\n",
    "    name = row['Player Name']\n",
    "    matches = process.extract(name, df_to_match[column_name], scorer=fuzz.partial_ratio)\n",
    "    best_match, score, _ = matches[0]\n",
    "    return best_match if score >= 80 else None\n",
    "\n",
    "player_id_mapping = pd.read_csv(\"player_id_mapping.csv\")\n",
    "player_id_mapping = player_id_mapping.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1dc615-6f77-41ac-9dfc-0604db6f90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_files = {\n",
    "    'QB': 'qb_career.csv',\n",
    "    'offense': 'offense_career.csv',\n",
    "    'defense': 'defense_career.csv',\n",
    "    'center': 'center_career.csv',\n",
    "    'ol': 'ol_career.csv',\n",
    "    'punting': 'punting_career.csv',\n",
    "    'kicking': 'kicking_career.csv'\n",
    "}\n",
    "\n",
    "career_dfs = {key: pd.read_csv(filename, index_col=0) for key, filename in career_files.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b753fcc-3ce8-41e5-a9d3-17e4073cdbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in career_dfs.items():\n",
    "\n",
    "    df['matched_name'] = df.apply(lambda row: fuzzy_match(row, player_id_mapping, 'player_name'), axis=1)\n",
    "\n",
    "    merged_df = df.merge(\n",
    "        player_id_mapping,\n",
    "        left_on='matched_name',\n",
    "        right_on='player_name',\n",
    "        how='left',\n",
    "        suffixes=('', '_original')\n",
    "    )\n",
    "\n",
    "    df['player_id'] = merged_df['player_id']\n",
    "    df = df.dropna(subset=['player_id'])\n",
    "    df = df.drop(columns=['matched_name'])\n",
    "    df['player_id'] = df['player_id'].astype(int)\n",
    "    career_dfs[key] = df\n",
    "\n",
    "\n",
    "qb_career = career_dfs['QB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80c5ac-ba71-4f8a-a205-a3f88d730fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_clusters = {pos: df for pos, df in quant_clusters.items() if pos in qualitative_displacement_positions}\n",
    "print(quant_clusters.get('WR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b55fac-9580-49fd-93ce-df2f09de4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_qb_career_success(df):\n",
    "    volume_features = ['Pass Yds', 'Cmp', 'TD', 'G', 'GS']\n",
    "    efficiency_features = ['Cmp%', 'Y/A', 'AY/A', 'TD%', 'Int', 'Rate', 'ANY/A']\n",
    "    decision_features = ['Succ%', 'Sk%', 'Int']\n",
    "    clutch_features = ['4QC', 'GWD']\n",
    "    composite_feature = ['AV']\n",
    "    \n",
    "    all_features = volume_features + efficiency_features + decision_features + clutch_features + composite_feature\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df[all_features]), columns=all_features, index=df.index)\n",
    "\n",
    "    for col in ['Int', 'Sk%']:\n",
    "        if col in df_scaled.columns:\n",
    "            df_scaled[col] = 1 - df_scaled[col]\n",
    "\n",
    "    df['career_success'] = (\n",
    "        0.10 * df_scaled[clutch_features].mean(axis=1) +\n",
    "        0.10 * df_scaled[volume_features].mean(axis=1) +\n",
    "        0.25 * df_scaled[efficiency_features].mean(axis=1) +\n",
    "        0.45 * df_scaled[decision_features].mean(axis=1) +\n",
    "        0.10 * df_scaled['AV']\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc969db4-4cfa-4588-91bf-29ceadae7f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_defense_career_success(df):\n",
    "    volume_features = ['G', 'GS', 'Comb', 'Solo', 'Ast']\n",
    "    impact_features = ['Sk', 'TFL', 'QBHits', 'FF', 'FR', 'Int', 'PD', 'Sfty']\n",
    "    composite_feature = ['AV']\n",
    "\n",
    "    all_features = volume_features + impact_features + composite_feature\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(scaler.fit_transform(df[all_features]), columns=all_features, index=df.index)\n",
    "\n",
    "    df['career_success'] = (\n",
    "        0.25 * df_scaled[volume_features].mean(axis=1) +\n",
    "        0.25 * df_scaled[impact_features].mean(axis=1) +\n",
    "        0.50 * df_scaled['AV']\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd97e63-13f6-4dfc-b017-f62da955c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_center_career_success(df):\n",
    "    durability = ['G', 'GS']\n",
    "    offense = ['Offense Snaps', 'Offense Pct']\n",
    "    special_teams = ['Special Teams Snaps', 'Special Teams Pct']\n",
    "\n",
    "    all_features = durability + offense + special_teams\n",
    "\n",
    "    df = df.dropna(subset=all_features)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df[all_features]),\n",
    "        columns=all_features,\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df['career_success'] = (\n",
    "        0.3 * df_scaled[durability].mean(axis=1) +\n",
    "        0.5 * df_scaled[offense].mean(axis=1) +\n",
    "        0.2 * df_scaled[special_teams].mean(axis=1)\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f4d84-3b5c-490c-a62c-ff9bf8eeb793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wr_career_success(df):\n",
    "    volume = ['Rec', 'Rec Yds', 'Rec TD', 'Tgt', 'G', 'GS']\n",
    "    efficiency = ['Ctch%', 'Y/R', 'Y/Tgt', 'Rec Succ%', 'Rush Succ%']\n",
    "    explosiveness = ['YScm', 'Y/Tch', 'Touch', 'RRTD']\n",
    "    rushing = ['Att', 'Rush Yds', 'Rush TD', 'Rush Succ%']\n",
    "    composite_feature = ['AV']\n",
    "\n",
    "    \n",
    "    all_features = volume + efficiency + explosiveness + rushing + composite_feature\n",
    "    df = df.dropna(subset=all_features)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(df[all_features]),\n",
    "        columns=all_features,\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    df['career_success'] = (\n",
    "        0.30 * df_scaled[volume].mean(axis=1) +\n",
    "        0.30 * df_scaled[efficiency].mean(axis=1) +\n",
    "        0.10 * df_scaled[explosiveness].mean(axis=1) +\n",
    "        0.10 * df_scaled[rushing].mean(axis=1) +\n",
    "        0.20 * df_scaled['AV']\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5efd8-4c97-46b5-b39a-99116b30044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_success(df, position):\n",
    "    if position == 'QB':\n",
    "        df = compute_qb_career_success(df)\n",
    "    elif position in ['DT', 'LB', 'DE']:\n",
    "        df = compute_defense_career_success(df)\n",
    "    elif position == 'OG':\n",
    "        df = compute_center_career_success(df)\n",
    "    elif position == 'WR':\n",
    "        df = compute_wr_career_success(df)\n",
    "    else:\n",
    "        print(f'Success for position unknown: {position}')\n",
    "        return df\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405b61e-ba0b-4a77-9b3f-876d478494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualitative_displacement_positions = ['QB', 'DT', 'FB', 'LB', 'OG', 'DE', 'WR']\n",
    "\n",
    "career_source_map = {\n",
    "    'QB': ('QB', None),\n",
    "    'DT': ('defense', 'DT'),\n",
    "    'FB': ('offense', 'FB'),\n",
    "    'LB': ('defense', 'LB'),\n",
    "    'OG': ('center', 'G'),\n",
    "    'DE': ('defense', 'DE'),\n",
    "    'WR': ('offense', 'WR'),\n",
    "}\n",
    "\n",
    "merged_clusters = {}\n",
    "merged_clusters_pick = {}\n",
    "\n",
    "for pos in qualitative_displacement_positions:\n",
    "\n",
    "    career_key, filter_pos = career_source_map.get(pos, (None, None))\n",
    "    career_df = career_dfs.get(career_key)\n",
    "    if career_df is None:\n",
    "        print(f\"No career data available\")\n",
    "        continue\n",
    "\n",
    "    if filter_pos:\n",
    "        career_df = career_df[career_df['Position'] == filter_pos]\n",
    "\n",
    "    quant_df = quant_clusters.get(pos)\n",
    "\n",
    "    merged_df = career_df.merge(quant_df, on='player_id', how='left')\n",
    "    merged_clusters[pos] = merged_df\n",
    "    merged_clusters[pos] = merged_clusters[pos].drop(columns = ['Unnamed: 0', 'player_name', 'pos_abbr', 'draft_year'])\n",
    "    merged_clusters[pos] = merged_clusters[pos].dropna(subset = ['cluster'])\n",
    "    merged_clusters[pos] = merged_clusters[pos][merged_clusters[pos]['Draft Year'] <= 2020]\n",
    "    merged_clusters_pick[pos] = merged_clusters[pos].copy()\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    merged_clusters[pos]['Pick'] = np.log(merged_clusters[pos]['Pick'] + 1)\n",
    "    merged_clusters[pos]['Pick'] = scaler.fit_transform(merged_clusters[pos][['Pick']])\n",
    "    update = get_success(merged_clusters[pos], pos)\n",
    "    merged_clusters[pos] = update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca676e-97ec-4408-98ad-5a46987a955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_clusters['WR'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44820e4-1794-422d-b2ab-72b4bd5eb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_source_map = {\n",
    "    'QB': ('QB', None),\n",
    "    'DT': ('defense', 'DT'),\n",
    "    'FB': ('offense', 'FB'),\n",
    "    'LB': ('defense', 'LB'),\n",
    "    'OG': ('center', 'G'),\n",
    "    'DE': ('defense', 'DE'),\n",
    "    'WR': ('offense', 'WR'),\n",
    "}\n",
    "\n",
    "position_models = {}\n",
    "\n",
    "for pos, df in merged_clusters.items():\n",
    "    if pos == 'FB':\n",
    "        continue\n",
    "\n",
    "    models = {}\n",
    "\n",
    "    # Model 1\n",
    "    X1 = df[['Pick']]\n",
    "    X1 = sm.add_constant(X1)\n",
    "    y1 = df['career_success']\n",
    "    models['pick'] = sm.OLS(y1, X1).fit()\n",
    "\n",
    "    # Model 2\n",
    "    career_key, filter_pos = career_source_map.get(pos, (None, None))\n",
    "    career_df = career_dfs.get(career_key)\n",
    "\n",
    "    if career_df is not None:\n",
    "        if filter_pos:\n",
    "            career_df = career_df[career_df['Position'] == filter_pos]\n",
    "        exclude = set(career_df.columns) | {'cluster', 'career_success'}\n",
    "    else:\n",
    "        print(f'No data for this position. Recheck careers')\n",
    "        exclude = {'cluster', 'career_success'}\n",
    "        \n",
    "    selected_cols = [col for col in df.columns if col not in exclude]\n",
    "    X2 = df[['Pick'] + selected_cols].copy()\n",
    "    y2 = df['career_success']\n",
    "    X2 = sm.add_constant(X2)\n",
    "    models['pick_top_quant'] = sm.OLS(y2, X2).fit()\n",
    "\n",
    "    # Model 3 \n",
    "    df_model = pd.get_dummies(df, columns = ['cluster'], prefix = 'cluster', drop_first = False)\n",
    "    y3 = df_model['career_success']\n",
    "    cluster_cols = [col for col in df_model.columns if col.startswith('cluster_')]\n",
    "    df_model[cluster_cols] = df_model[cluster_cols].astype(int)\n",
    "\n",
    "    X3 = df_model[['Pick'] + cluster_cols]\n",
    "    models['pick_quant_clusters'] = sm.OLS(y3, X3).fit()\n",
    "\n",
    "\n",
    "    position_models[pos] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeae9c8-aafe-43ce-8816-2c88b9077817",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_labels = ['pick', 'pick_top_quant', 'pick_quant_clusters']\n",
    "\n",
    "for pos, result in position_models.items():\n",
    "    if pos == 'LB':\n",
    "        print(pos)\n",
    "        for t in table_labels:\n",
    "            print(position_models[pos][t].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec26df0-5955-405b-9c91-846c4459eb93",
   "metadata": {},
   "source": [
    "# Avg Pick per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f408c-bd8f-4727-a434-91f115580c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_to_check = ['QB', 'DT', 'FB', 'LB', 'OG', 'DE', 'WR']\n",
    "\n",
    "avg_pick_by_cluster = {}\n",
    "\n",
    "for pos in positions_to_check:\n",
    "    \n",
    "    df = merged_clusters_pick[pos]\n",
    "    df['cluster'] = df['cluster'].astype(str)\n",
    "    cluster_avg = df.groupby('cluster')['Pick'].mean().sort_index()\n",
    "    avg_pick_by_cluster[pos] = cluster_avg\n",
    "\n",
    "for pos, cluster_stats in avg_pick_by_cluster.items():\n",
    "    print(f\"\\nPosition: {pos}\")\n",
    "    print(cluster_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26340bd6-5b6d-4265-91c8-baa87c632040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f1a3c-e505-4f87-b013-664f8e83dd71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
